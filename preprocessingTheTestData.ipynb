{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNP6jkZvYglT0sdy5VFTex6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sachinkumar-jpg/machine-learning/blob/main/preprocessingTheTestData.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "zO1rG1XutgjA"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "\n",
        "\n",
        "# Load your dataset (replace 'your_dataset.csv' with the actual file path)\n",
        "data = pd.read_csv('/content/test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Identify features with missing values\n",
        "missing_values = data.isnull().sum()\n",
        "\n",
        "# Step 2: Decide on an appropriate strategy for each feature\n",
        "for feature, missing_count in missing_values.iteritems():\n",
        "    if missing_count > 0:\n",
        "        print(f\"Feature '{feature}' has {missing_count} missing values.\")\n",
        "\n",
        "        # Decide on a strategy:\n",
        "        # Example 1: Impute missing values with the mean\n",
        "        if data[feature].dtype == 'float64':\n",
        "            mean_value = data[feature].mean()\n",
        "            data[feature].fillna(mean_value, inplace=True)\n",
        "            print(f\"Strategy: Imputed missing values with mean value {mean_value}\")\n",
        "\n",
        "        # Example 2: Delete rows with missing values\n",
        "        # data.dropna(subset=[feature], inplace=True)\n",
        "        # print(\"Strategy: Deleted rows with missing values\")\n",
        "\n",
        "        # You can define other strategies as needed\n",
        "\n",
        "# Optionally, save the modified dataset to a new file\n",
        "# data.to_csv('new_dataset.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yToVzcahdQa4",
        "outputId": "fb375f82-e848-4a76-d0ed-d8fb2445d8f3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature 'MSZoning' has 4 missing values.\n",
            "Feature 'LotFrontage' has 227 missing values.\n",
            "Strategy: Imputed missing values with mean value 68.58035714285714\n",
            "Feature 'Alley' has 1352 missing values.\n",
            "Feature 'Utilities' has 2 missing values.\n",
            "Feature 'Exterior1st' has 1 missing values.\n",
            "Feature 'Exterior2nd' has 1 missing values.\n",
            "Feature 'MasVnrType' has 16 missing values.\n",
            "Feature 'MasVnrArea' has 15 missing values.\n",
            "Strategy: Imputed missing values with mean value 100.70914127423822\n",
            "Feature 'BsmtQual' has 44 missing values.\n",
            "Feature 'BsmtCond' has 45 missing values.\n",
            "Feature 'BsmtExposure' has 44 missing values.\n",
            "Feature 'BsmtFinType1' has 42 missing values.\n",
            "Feature 'BsmtFinSF1' has 1 missing values.\n",
            "Strategy: Imputed missing values with mean value 439.2037037037037\n",
            "Feature 'BsmtFinType2' has 42 missing values.\n",
            "Feature 'BsmtFinSF2' has 1 missing values.\n",
            "Strategy: Imputed missing values with mean value 52.61934156378601\n",
            "Feature 'BsmtUnfSF' has 1 missing values.\n",
            "Strategy: Imputed missing values with mean value 554.2949245541838\n",
            "Feature 'TotalBsmtSF' has 1 missing values.\n",
            "Strategy: Imputed missing values with mean value 1046.1179698216736\n",
            "Feature 'BsmtFullBath' has 2 missing values.\n",
            "Strategy: Imputed missing values with mean value 0.4344543582704187\n",
            "Feature 'BsmtHalfBath' has 2 missing values.\n",
            "Strategy: Imputed missing values with mean value 0.06520247083047358\n",
            "Feature 'KitchenQual' has 1 missing values.\n",
            "Feature 'Functional' has 2 missing values.\n",
            "Feature 'FireplaceQu' has 730 missing values.\n",
            "Feature 'GarageType' has 76 missing values.\n",
            "Feature 'GarageYrBlt' has 78 missing values.\n",
            "Strategy: Imputed missing values with mean value 1977.7212165097756\n",
            "Feature 'GarageFinish' has 78 missing values.\n",
            "Feature 'GarageCars' has 1 missing values.\n",
            "Strategy: Imputed missing values with mean value 1.7661179698216736\n",
            "Feature 'GarageArea' has 1 missing values.\n",
            "Strategy: Imputed missing values with mean value 472.76886145404666\n",
            "Feature 'GarageQual' has 78 missing values.\n",
            "Feature 'GarageCond' has 78 missing values.\n",
            "Feature 'PoolQC' has 1456 missing values.\n",
            "Feature 'Fence' has 1169 missing values.\n",
            "Feature 'MiscFeature' has 1408 missing values.\n",
            "Feature 'SaleType' has 1 missing values.\n",
            "Feature 'SalePrice' has 1459 missing values.\n",
            "Strategy: Imputed missing values with mean value nan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-28954ceccef7>:5: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for feature, missing_count in missing_values.iteritems():\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "column_to_remove = 'Id'  # Replace 'column_name' with the actual column name\n",
        "\n",
        "# Remove the specified column from the dataset\n",
        "data = data.drop(columns=[column_to_remove])\n",
        "\n",
        "# Optionally, save the modified dataset to a new file\n",
        "data.to_csv('dataset_without_column.csv', index=False)"
      ],
      "metadata": {
        "id": "N9_-TNj6deo9"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Iterate through columns and encode non-numeric values\n",
        "for column in data.columns:\n",
        "    if data[column].dtype == 'object':\n",
        "        data[column] = label_encoder.fit_transform(data[column])\n",
        "\n",
        "# Optionally, save the encoded dataset to a new file\n",
        "data.to_csv('encoded_dataset.csv', index=False)"
      ],
      "metadata": {
        "id": "A33bEqgUdlBT"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_filled = data.fillna(data.mean())\n",
        "\n",
        "# Optionally, save the dataset with missing values filled to a new file\n",
        "data_filled.to_csv('filled_dataset.csv', index=False)"
      ],
      "metadata": {
        "id": "sei8iLvhdqR2"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z_score_threshold = 3.0\n",
        "\n",
        "# Calculate the Z-scores for each column\n",
        "z_scores = np.abs((data - data.mean()) / data.std())\n",
        "\n",
        "# Find rows with any Z-score exceeding the threshold\n",
        "outlier_rows = z_scores[(z_scores > z_score_threshold).any(axis=1)].index\n",
        "\n",
        "# Remove outliers from the dataset\n",
        "data_no_outliers = data.drop(outlier_rows)\n",
        "\n",
        "# Optionally, save the dataset without outliers to a new file\n",
        "data_no_outliers.to_csv('data_no_outliers.csv', index=False)"
      ],
      "metadata": {
        "id": "qLA73ioCdytX"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select the numerical columns for normalization or standardization\n",
        "numerical_columns = data.select_dtypes(include=['float64', 'int64']).columns\n",
        "\n",
        "# Apply Min-Max normalization to the numerical columns\n",
        "scaler_minmax = MinMaxScaler()\n",
        "data[numerical_columns] = scaler_minmax.fit_transform(data[numerical_columns])\n",
        "\n",
        "# Optionally, save the dataset with Min-Max normalized values to a new file\n",
        "# data.to_csv('minmax_normalized_dataset.csv', index=False)\n",
        "\n",
        "# Apply Z-score standardization to the numerical columns\n",
        "scaler_standard = StandardScaler()\n",
        "data[numerical_columns] = scaler_standard.fit_transform(data[numerical_columns])\n",
        "\n",
        "# Optionally, save the dataset with Z-score standardized values to a new file\n",
        "data.to_csv('standardized_dataset.csv', index=False)"
      ],
      "metadata": {
        "id": "LCVAjxuFd3Se"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}